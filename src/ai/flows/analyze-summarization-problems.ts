
'use server';
/**
 * @fileOverview A Genkit flow that analyzes generated summaries to categorize
 * underlying problems or areas for improvement.
 *
 * - analyzeSummarizationProblems - A function that takes generated summaries and context,
 *   then returns categorized problems with counts and examples.
 * - AnalyzeSummarizationProblemsInput - The input type.
 * - AnalyzeSummarizationProblemsOutput - The output type.
 * - SummarizationProblemCategory - Represents a categorized problem for summaries.
 */

import {ai} from '@/ai/genkit';
import { z } from 'genkit';

// Input Schema
const GeneratedSummaryDetailSchema = z.object({
  inputData: z.record(z.string(), z.any()).describe("The product parameters input for the row that produced this summary."),
  generatedSummary: z.string().describe("The actual summary text generated by the LLM."),
});

const AnalyzeSummarizationProblemsInputSchema = z.object({
  generatedSummaryDetails: z.array(GeneratedSummaryDetailSchema).describe("An array of objects, each detailing a specific input and its generated summary."),
  targetSummarizationDefinitionName: z.string().describe("The name of the summarization definition that is being analyzed."),
  targetSummarizationDefinitionText: z.string().describe("The full definition text of the target summarization task (what the summary was supposed to achieve)."),
  productSchemaDescription: z.string().optional().describe("A textual description of the schema for product parameters (e.g., field names, types, descriptions) that were available as inputs to the original product prompt, which generated the summary."),
});
export type AnalyzeSummarizationProblemsInput = z.infer<typeof AnalyzeSummarizationProblemsInputSchema>;

// Output Schema
const SummarizationProblemCategorySchema = z.object({
  categoryName: z.string().describe("A concise, descriptive name for the identified problem category (e.g., 'Missing Key Information', 'Too Verbose', 'Incorrect Focus', 'Poor Cohesion')."),
  description: z.string().describe("A brief explanation of what this problem category entails and why it leads to a suboptimal summary."),
  count: z.number().int().describe("The number of provided summary details that exhibit this problem category. This should be a positive integer."),
  exampleSummaryIssue: z.object({
      inputData: z.string().describe("The product parameters input for the row, formatted as a JSON string."),
      generatedSummary: z.string().describe("The generated summary that illustrates this problem."),
    }).optional().describe("One example GeneratedSummaryDetail from the input that clearly illustrates this problem category. Include this if possible. Its 'inputData' field MUST be a JSON string representation of the original input data object.")
});
export type SummarizationProblemCategory = z.infer<typeof SummarizationProblemCategorySchema>;

const AnalyzeSummarizationProblemsOutputSchema = z.object({
  problemCategories: z.array(SummarizationProblemCategorySchema).describe("An array of identified problem categories related to summarization quality, each with a name, description, count of occurrences, and an optional example."),
  overallSummaryOfIssues: z.string().optional().describe("A brief overall summary of the key issues identified in the generated summaries, if applicable.")
});
export type AnalyzeSummarizationProblemsOutput = z.infer<typeof AnalyzeSummarizationProblemsOutputSchema>;


export async function analyzeSummarizationProblems(
  input: AnalyzeSummarizationProblemsInput
): Promise<AnalyzeSummarizationProblemsOutput> {
  return internalAnalyzeSummarizationProblemsFlow(input);
}

const handlebarsPrompt = `
You are an expert AI Product Analyst specializing in evaluating the quality of AI-generated summaries.
Your task is to analyze a set of "generated summaries" against a specific 'Target Summarization Definition'.
Your goal is to identify common problems, shortcomings, or areas for improvement in these summaries, categorize them, and count how many instances fall into each category.
This analysis will help the product creator understand how to refine their prompts or models to produce better summaries.

Context:
- Target Summarization Definition Name: "{{targetSummarizationDefinitionName}}"
- Target Summarization Definition Text:
  \`\`\`
  {{{targetSummarizationDefinitionText}}}
  \`\`\`

{{#if productSchemaDescription}}
- Product Input Parameters Schema (used in the original prompt that led to these summaries):
{{{productSchemaDescription}}}
{{/if}}

Generated Summary Details:
{{#each generatedSummaryDetails}}
Summary Example:
  - Input Data Provided to Product: {{{json inputData}}}
  - Generated Summary by LLM: "{{generatedSummary}}"
---
{{/each}}

Instructions:
1.  Carefully review all the provided generated summary details and the 'Target Summarization Definition Text'.
2.  For each generated summary, assess its quality and relevance based on the definition. Consider:
    - Does it capture the key information specified in the definition?
    - Is it concise and to the point?
    - Is it accurate based on the input data?
    - Is it well-structured and coherent?
    - Does it meet any specific constraints or goals mentioned in the definition?
3.  Identify common themes, patterns, or root causes for any identified shortcomings. These are your "problem categories".
    Examples of problem categories could be:
    - "Summary omits critical details from input."
    - "Generated summary is too verbose/lengthy for the defined purpose."
    - "Summary incorrectly interprets or misrepresents the input data."
    - "The summary focuses on less relevant aspects of the input."
    - "Lack of clarity or cohesion in the generated summary."
4.  Group the summaries with issues into these distinct problem categories. A single summary might exhibit characteristics of multiple problems, but try to assign it to the most prominent one or note the overlap if significant.
5.  For each category, provide:
    - 'categoryName': A concise name for the problem category.
    - 'description': A brief explanation of this problem category.
    - 'count': The number of summary instances that fall into this category. This should be a positive integer.
    - 'exampleSummaryIssue': (Optional, but highly recommended) Select one GeneratedSummaryDetail from the input that clearly illustrates this problem category. If you include an example, its 'inputData' field MUST be a JSON string.

Your entire response must be ONLY a JSON object matching the output schema, with no other surrounding text or explanations.
The output schema expects a 'problemCategories' array and an optional 'overallSummaryOfIssues'.
Ensure the 'count' for each category accurately reflects how many of_the_provided summary examples fit that category.
`;

const analysisPrompt = ai.definePrompt({
  name: 'analyzeSummarizationProblemsPrompt',
  input: {schema: AnalyzeSummarizationProblemsInputSchema},
  output: {schema: AnalyzeSummarizationProblemsOutputSchema},
  prompt: handlebarsPrompt,
  config: {
    temperature: 0.5,
  },
});

const internalAnalyzeSummarizationProblemsFlow = ai.defineFlow(
  {
    name: 'internalAnalyzeSummarizationProblemsFlow',
    inputSchema: AnalyzeSummarizationProblemsInputSchema,
    outputSchema: AnalyzeSummarizationProblemsOutputSchema,
  },
  async (input) => {
    if (!input.generatedSummaryDetails || input.generatedSummaryDetails.length === 0) {
        return { problemCategories: [], overallSummaryOfIssues: "No summaries provided to analyze." };
    }

    const { output, usage } = await analysisPrompt(input);

    if (!output) {
      throw new Error('The LLM did not return a parsable output for summarization problem analysis.');
    }
    // console.log('internalAnalyzeSummarizationProblemsFlow LLM usage:', usage);
    // console.log('internalAnalyzeSummarizationProblemsFlow LLM output:', JSON.stringify(output, null, 2));
    return output!;
  }
);
